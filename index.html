<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>ASI-401: Indoor Search Using Swarm of Drones</title>
  <link rel="icon" href="./favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@shoelace-style/shoelace@2.16.0/cdn/themes/light.css" />
  <script type="module"
    src="https://cdn.jsdelivr.net/npm/@shoelace-style/shoelace@2.16.0/cdn/shoelace-autoloader.js"></script>

  <link rel="stylesheet" href="./index.css">

  <link rel="stylesheet" href="./components/left-nav-tab/left-nav-tab.css">

  <link rel="stylesheet" href="./components/team-member/team-member.css">
  <script type="module" src="./components/team-member/team-member.js"></script>

  <link rel="stylesheet" href="./components/table-of-content/table-of-content.css">

  <script type="module" src="./components/table-of-abbreviations/table-of-abbreviations.js"></script>
  
  <script type="module" src="./components/comparision-safmc/comparison-safmc.js"></script>

  <script type="module" src="./components/comparision-image-processing/comparison-image-processing.js"></script>
  
  <script type="module" src="./components/msba-configuration/msba-configuration.js"></script>

  <script type="module" src="./components/drone_platform_selection/drone_platform_selection.js"></script>

  <script type="module" src="./components/decision-matrix-pillar/decision-matrix-pillar.js"></script>

  <script type="module" src="./components/rc4-test-scores/rc4-test-scores.js"></script>

  <script type="module" src="./components/actual-test-scores/actual-test-scores.js"></script>

  <script type="module" src="./components/image/image-component.js"></script>

  <script type="module" src="components/image/image-full.js"></script>

  <script type="module" src="./components/video/video.js"></script>

  <link rel="stylesheet" href="./components/references/references.css">

  <link rel="stylesheet" href="./components/scroll-to-top/scroll-to-top.css">
  <script src="./components/scroll-to-top/scroll-to-top.js"></script>

  <script src="./components/table-component/table-component.js"></script>

  <link href="https://unpkg.com/gridjs/dist/theme/mermaid.min.css" rel="stylesheet" />
  
</head>

<body>

  <div class="sidenav">
    <ul type="none">
      <li><a href="#title"onclick="showSection('title')">Title</a></li>
      <li><a href="#acknowledgements"onclick="showSection('acknowledgements')">Acknowledgements</a></li>
      <li><a href="#table-of-abbreviation"onclick="showSection('table-of-abbreviation')">Table Of Abbreviations</a></li>
  
      <li>
        <a href="#section-header-1" onclick="showSection('section-header-1')">1. Singapore Amazing Flying Competition 2025</a>
        <ul type="none">
          <li><a href="#sub-section-1-header-1">1.1 Category E Mission</a></li>
          <li>
            <a href="#sub-section-1-header-2">1.2 Playing Field</a>
            <ul type="none">
              <li><a href="#sub-section-1-header-2-header-1">1.2.1 Known Search Area</a></li>
              <li><a href="#sub-section-1-header-2-header-2">1.2.2 Unknown Search Area</a></li>
              <li><a href="#sub-section-1-header-2-header-3">1.2.3 Pillar Area</a></li>
            </ul>
          </li>
          <li><a href="#sub-section-1-header-3">1.3 Victim Marker</a></li>
          <li><a href="#sub-section-1-header-4">1.4 Danger Zone</a></li>
          <li><a href="#sub-section-1-header-5">1.5 Navigation Aid</a></li>
          <li><a href="#sub-section-1-header-6">1.6 Pillar Obstacle</a></li>
          <li><a href="#sub-section-1-header-7">1.7 SAFMC 2025 vs SAFMC 2024</a></li>
        </ul>
      </li>
  
      <li>
        <a href="#section-header-2" onclick="showSection('section-header-2')">2. Selected Drone Platform</a>
        <ul type="none">
          <li><a href="#sub-section-2-header-1">2.1 Hardware: Bitcraze Crazyflie</a></li>
          <li><a href="#sub-section-2-header-2">2.2 Drone Software and Development</a></li>
        </ul>
      </li>
  
      <li>
        <a href="#section-header-3" onclick="showSection('section-header-3')">3. Mission Strategy</a>
        <ul type="none">
          <li><a href="#sub-section-3-header-1">3.1 Search Strategy</a></li>
          <li><a href="#sub-section-3-header-2">3.2 Object Detection</a></li>
          <li><a href="#sub-section-3-header-3">3.3 Navigation Aids</a></li>
          <li><a href="#sub-section-3-header-4">3.4 Key Areas of Development</a></li>
        </ul>
      </li>
       <li>
          <a href="#section-header-4" onclick="showSection('section-header-4')">4. Object Detection (Shu Hui)</a>
        <ul type="none">
          <li><a href="#sub-section-4-header-1">4.1 Object Selection</a></li>
          <li><a href="#sub-section-4-header-2">4.2 Onboard Object Detection</a></li>
          <li><a href="#sub-section-4-header-3">4.3 Offboard Object Detection</a></li>
          <li><a href="#sub-section-4-header-4">4.4 Optimising Detection Parameters for the Drone</a></li>
          <li><a href="#sub-section-4-header-5">4.5 External System Optimisation</a></li>
        </ul>
      </li>

      <li>
        <a href="#section-header-5" onclick="showSection('section-header-5')">5. Known Search Area (Yan Yew)</a>
        <ul type="none">
          <li><a href="#sub-section-5-header-1">5.1 Selection of Search Algorithms</a></li>
          <li><a href="#sub-section-5-header-2">5.2 Modified Swarm Bug Algorithm</a></li>
          <li><a href="#sub-section-5-header-3">5.3 Initial Proposal Strategy Using MSBA</a></li>
          <li><a href="#sub-section-5-header-4">5.4 Simulation to Evaluate Search Strategy</a></li>
          <li><a href="#sub-section-5-header-5">5.5 Improvements to MSBA</a></li>
          <li><a href="#sub-section-5-header-6">5.6 Real Life Testing</a></li>
          <li><a href="#sub-section-5-header-7">5.7 Final MSBA Parameters</a></li>

        </ul>
      </li>

      <li>
        <a href="#section-header-6" onclick="showSection('section-header-6')">6. UnKnown Search Area (Yan Yew)</a>
        <ul type="none">
          <li><a href="#sub-section-6-header-1">6.1 Feasibility Resting of Simulatanous Mapping and Localisation</a></li>
            <li>
            <a href="#sub-section-6-header-2">6.2 Implementation of MSBA</a>
            <ul type="none">
              <li><a href="#sub-section-6-header-2-header-1">6.2.1 Drone Guidance to the Unknown Area</a></li>
              <li><a href="#sub-section-6-header-2-header-2">6.2.2 MSBA for Searching the Unknown Area</a></li>
            </ul>
          </li>     
          <li><a href="#sub-section-6-header-3">6.3 Integration with Mission Planner</a></li>
          <li><a href="#sub-section-6-header-4">6.4 Real Life Testing</a></li>

        </ul>
      </li>
  
      <li>
        <a href="#section-header-7" onclick="showSection('section-header-7')">7.Pillar Area (Matthew)</a>
        <ul type="none">
          <li><a href="#sub-section-7-header-1">7.1 Introduction to the Pillar Area</a></li>
          <li><a href="#sub-section-7-header-2">7.2 Mock-Up of the Pillar Area</a></li>
          <li><a href="#sub-section-7-header-3">7.3 Testing of Search Strategies Within</a></li>
          <li><a href="#sub-section-7-header-4">7.4 Testing of Victim placement</a></li>
          <li>
            <a href="#sub-section-7-header-5">7.5 Optimising for Search and Rescue</a>
            <ul type="none">
              <li><a href="#sub-section-7-header-5-header-1">7.5.1 Sliding to the Side When Near a Pillar</a></li>
              <li><a href="#sub-section-7-header-5-header-3">7.5.2 Optimising the speed of the drones</a></li>
              <li><a href="#sub-section-7-header-5-header-3">7.5.3 Navigation Aid to Reverse at the End of the Pillar Area</a></li>
              <li><a href="#sub-section-7-header-5-header-3">7.5.4 Straight line vs Zig-Zag path</a></li>
            </ul>
          </li> 
          <li><a href="#sub-section-7-header-6">7.6 Full Algorithm</a></li>
        </ul>
      </li>
  
      <li>
        <a href="#section-header-8" onclick="showSection('section-header-8')">8. Mission Planning (Shu Hui)</a>
        <ul type="none">
          <li><a href="#sub-section-8-header-1">8.1 Optimisation of Take-off Sequence</a></li>
          <li><a href="#sub-section-8-header-2">8.2 Optimisation of Kill and Landing Sequence</a></li>
          <li><a href="#sub-section-8-header-3">8.3 Communication Between the Ground Control Station and Drones</a></li>
        </ul>
      </li>
  
      <li>
        <a href="#section-header-9" onclick="showSection('section-header-9')">9. Full-Scale Systems Testing</a>
        <ul type="none">
          <li>
            <a href="#sub-section-9-header-1">9.1 Testing in Residential College 4 Multi-Purpose Sports Hall</a>
            <ul type="none">
              <li><a href="#sub-section-9-header-1-header-1">9.1.1 Network and Bandwidth Issues</a></li>
              <li><a href="#sub-section-9-header-1-header-2">9.1.2 Different Performance of the Drones in Different Conditions</a></li>
              <li><a href="#sub-section-9-header-1-header-3">9.1.3 Overall Analysis</a></li>
            </ul>
          </li>
          <li><a href="#sub-section-9-header-2">9.2 Competition Day</a></li>
        </ul>
      </li>
  
      <li>
        <a href="#section-header-10" onclick="showSection('section-header-10')">10. Conclusion and Future Work</a>
        <ul type="none">
          <li><a href="#sub-section-10-header-1">10.1 Smart stuff</a></li>
        </ul>
      </li>
  
      <li><a href="#appendices" onclick="showSection('appendices')">Appendix A: Decision Matrix for Selection of Drone Development Platform</a></li>

      <li><a href="#references" onclick="showSection('references')">References</a></li>
    </ul>
  </div>

  <div class="content">
    <div class = "title">
    <div id="title"></div>
      
      <image-component tag="image" source="assets/title_page/nus_logo.png" subtitle=" ">
      </image-component>

      <h1>CDE4301 Innovation & Design Capstone</h1>

      <h1>AY2024/2025 Semester 2</h1>

      <h1>ASI-401: Indoor Search Using Swarm of Drones</h1>

      <h1>Group Report</h1>
      </div>

      <div class="team-member-wrapper">

      <team-member avatar="assets//title_page/shuhui.jpeg" name="Foo Shu Hui" department="Engineering Science Programme" 
       matric_number="A0244238E">
      </team-member>

      <team-member avatar="assets//title_page/yanyew.jpg" name="Low Yan Yew" department="Mechanical Engineering"
        matric_number="A0245906Y">
      </team-member>

      <team-member avatar="assets//title_page/samuel.png" name="Govindanath Samuel Sudharsanan" department="Mechanical Engineering"
        matric_number="A0239048Y">
      </team-member>

      <team-member avatar="assets/title_page/matthew.png" name="Matthew Yip Tze Herng" department="Mechanical Engineering"
        matric_number="A0249201N">
      </team-member>

    </div>

    <br />
    <br />

    <div id="acknowledgements" class ="acknowledgements" >
      
      <h2>Acknowledgements</h2>
      
      <p>We would like to extend our heartfelt gratitude to everyone who has contributed to our project in one way or another. Your support has been invaluable in ensuring its smooth progress, and we could not have accomplished this without you.</p>
      <p><strong>Project Supervisors</strong></p>
      <ul>
        <li>Dr. Elliot Law, Project Supervisor</li>
        <li>Mr. Nicholas Chew, Co-Project Supervisor</li>
      </ul>
     <p><strong>Temasek Lab & SAFMC Team</strong></p>
     <ul>    
        <li>Mr. Liew Yung Jun, Temasek Lab Staff, SAFMC 2024 Team Member</li>
        <li>Mr. Jimmy Chiun, Temasek Lab Staff, Former SAFMC Team Member</li>
        <li>Mr. William Leong, Temasek Lab Staff, Former SAFMC Team Member</li>
     </ul>
     <p><strong>EDIC Staff</strong></p>
    <ul>  
      <li>Ms. Annie Tan</li>
      <li>Mr. Alvin Poh</li>
    </ul>
    <p><strong>Residential College 4 (RC4) Staff & Directors</strong></p>
    <ul>   
      <li>Dr. Naviyn Prabhu Balakrishnan, Director of Student Life</li>
      <li>Mr. Scormon Ho Rui Sheng, Director of Sports</li>
      <li>Ms. Chloe Siew Ying Ning, Director of Clubs and Societies</li>
      <li>Ms. Ngu Hui Tze, Admin Staff</li>
      <li>Ms. Loi Hwee Fang, Admin Staff</li>
      <li>Mr. Tan You Cheng, Admin Staff</li>
    </ul>
    </div>

    <br />
    <br />

    <div class="table-of-abbreviations">
      <h2>Table of Abbreviations</h2>
      <div id="table-of-abbreviation"></div>

    </div>
    
    <br />
    <br />

    <div id = "main-content">

      <div id="section-header-1" class="section" style="display: none;">
        <h2>1. Singapore Amazing Flying Machine Competition 2025</h2>
        <p>
          Our group is participating in Singapore Amazing Flying Machine Competition (SAFMC) 2025 Open Category (Category E). In this category, we are required to design an autonomous drone swarm to search and rescue for victims in a given area.
          <br/><br/>
          Drone swarms have been used in a variety of real-world implementations, including environmental mapping and search and rescue. Defence Science Organisation (DSO), the organiser of the competition, stands to gain technical know-how from organising this competition. This can be applied in their development of drone systems for defence.
        </p>
      

      <div id="sub-section-1-header-1">
        <h3>1.1 Category E Mission</h3>

        <p>
          The mission of SAFMC 2025 Category E is: <br/><br/>

          <i>Design a system of <b>10 to 25 drones</b> to navigate through an <b>indoor environment</b> and search for victims,
          using either a <b>centralised</b> or <b>de-centralised</b> <u>fully autonomous control system</u>. The system must possess
          <b>localization</b>, <b>obstacle sensing</b> and <b>obstacle avoidance</b> capabilities.</i>
        </p>
      </div>

      <div id="sub-section-1-header-2">
        <h3>1.2 Playing Field</h3>
        <p>
          Figure 1.3 shows how the Arena this year will look like, which is not drawn to scale. Furthermore, the Danger Zones, Regular Victims and Bonus Victims may not be placed exactly where it is depicted in Figure 1.3. There is a maximum of two simultaneous take-offs of two runs per team. For each run, the placement of Danger Zones, Regular Victims and Bonus Victims may change. 
        </p>

        <image-component tag="image" source="./assets/section-1-safmc2025/figure_1_1_SAFMC_2025_playing_field.png"
                         subtitle="Figure 1.1: Indoor Arena of SAFMC 2022"></image-component>

        <p>
          Figure 1.4 shows the dimensions of the key elements within the Arena.
        </p>

        <p>
          The Arena has a size of 20 m x 14 m. The Start Area (green) has a size of 20 m x 6 m.
          </p>
        
        <p>
          The Start Area is where the Crazyflies would take off from to start the mission. There is no limit to the number of Navigation Aids that can be used within the Start Area.
          </p>

        <p>
          For our analysis, we split the Arena into three sections: (1) Known Search Area (grey). (2) Unknown Search Area (yellow). (3) Pillar Area.
          </p>

      </div>

      <div id="sub-section-1-header-2-header-1">
        <h4>1.2.1 Known Search Area</h4>

        <image-component tag="image" source="assets\section-1-safmc2025\figure_1_2_known_search_area.png"
        subtitle="Figure 1.2: Known Search Area"></image-component>  

        <p>
          The Known Search Area (grey) have the dimensions of 20 m x 14 m, which is the largest area in the Arena. The Known Search Area (Figure 1.5) will have Inner Walls of 2 m thickness and 2 m height, as well as Danger Zones, Regular Victims and Bonus Victims. The Inner Wall-to-Inner Wall distance is at least 2 m. There is a maximum of Ten Navigation Aids that can be used within the Arena (exclusive of the Unknown Search Area). 
          </p>
         

      </div>

      <div id="sub-section-1-header-2-header-2">
        <h4>1.2.2 Unknown Search Area</h4>

        <image-component tag="image" source="assets\section-1-safmc2025\figure_1_3_unknown_search_area.png"
        subtitle="Figure 1.3: UnKnown Search Area"></image-component>  

        <p>
          The Unknown Search Area have the size of 8 m x 8 m and is situated in the centre of the Arena. The Unknown Search Area (Figure 1.6) contains Danger Zones, Inner Walls and Bonus Victims. There are two floor-to-ceiling entrances/exits to the Unknown Search Area.
          </p>
        
        <p>
          Navigation Aids are not allowed within the Unknown Search Area. Furthermore, the layout of the Unknown Search Area will not be revealed on Competition Day Mission.          
          </p>

      </div>

      <div id="sub-section-1-header-2-header-3">
        <h4>1.2.3 Pillar Area</h4>

        <image-component tag="image" source="assets\section-1-safmc2025\figure_1_4_pillar_area.png"
        subtitle="Figure 1.4: Pillar Area"></image-component>

        <p>
          The Pillar Area (Figure 1.7) is the smallest area in the Arena. It consists of Eight Pillars Obstacles, with narrow paths (about 1 m wide) between the Pillar Obstacles. The Inner Wall-to-Pillar distance and the Pillar-to-Pillar distance is at least 1 m.
          </p>

        <p>
          Figure 1.7 shows a Bonus Victim situated within the Pillar Area, which highlights the importance of developing a unique algorithm capable of navigating the Pillar Area.
          </p>

      </div>

      <div id="sub-section-1-header-3">
        <h3>1.3 Victim Marker</h3>

        <image-component tag="image" source="assets\section-1-safmc2025\figure_1_5_specifications_of_victim_markers.png"
        subtitle="Figure 1.5: Specifications of Victim Markers"></image-component>

        <p>
          For SAFMC 2025, eight non-electronic markers will be used as Victim Markers. Figure 1.8 shows the general specifications of the Victim Markers, which must not exceed 30 cm x 30 cm x 1 m. Figure 1.8 does not show the actual Victim Marker we are using for the competition.
          </p>

        <p>
          Both Regular Victim and Bonus Victim will share the same type of Victim Markers. However, the Bonus Victim will be situated in areas that are more challenging to navigate. 
          </p>

        <image-component tag="image" source="assets\section-1-safmc2025\figure_1_6_scoring_process_rescue_victims.png"
        subtitle="Figure 1.6: Scoring Process (Rescue Victims)"></image-component>
        
        <p>
          To rescue a Victim, the Crazyflie needs to land within a 1 m radius of the Line of Sight (LOS) of the Regular Victim or a Bonus Victim (Figure 1.9). No obstacles are allowed within the Line of Sight.
          </p>
        
          <p>
          Each Victim Marker can be rescued only once by one Crazyflie.
          </p>

        <p>
          If the Crazyflie rescues a Regular Victim, 5 points will be added to the total score. However, if the Crazyflie rescues a Bonus Victim, 15 points will be added to the total score.
          </p>
      </div>

      <div id="sub-section-1-header-4">
        <h3>1.4 Danger Zone</h3>

        <image-component tag="image" source="assets\section-1-safmc2025\figure_1_7_specifications_of_danger_zones.png"
        subtitle="Figure 1.7: Specifications of Danger Zones"></image-component>
        <p>
          For SAFMC 2025, four non-electronic markers will be used as Danger Zones. Figure 1.10 shows the general specifications of the Danger Zones, which must not exceed 30 cm x 30 cm x 1 m. Figure 1.10 does not show the actual Danger Zones we are using for the competition.
          </p>
        
        <p>
          Danger Zones may overlap with any navigation aids we place within the Arena.
        </p>

        <image-component tag="image" source="assets\section-1-safmc2025\figure_1_8_penalty_process_avoid_danger_zones.png"
        subtitle="Figure 1.8: Penalty Process (Avoid Danger Zones)"></image-component>

        <p>
          Crazyflies must not land within a 1 m radius of the Danger Zone. If they do, a penalty of 2 points will be removed from the total score (Figure 1.11). However, Crazyflies are allowed to fly over the Danger Zone, without landing within the 1 m radius.
        </p>

      </div>

      <div id="sub-section-1-header-5">
        <h3>1.5 Navigation Aid</h3>

        <image-component tag="image" source="assets\section-1-safmc2025\figure_1_9_specifications_of_navigation_aids.png"
        subtitle="Figure 1.9: Specifications of Navigation Aids"></image-component>
        
        <p>
          For SAFMC 2025, a total of ten Navigation Aids can be used within the Known Search Area and Pillar Area. Figure 1.12 shows the general specifications of the Navigation Aids, which must not exceed 1 m x 1 m x an unspecified height. Figure 1.12 does not show the actual Navigation Aids we are using for the competition.
          </p>

        <p>
          Figure 1.13 shows the types of Navigation Aids the team is currently exploring. These physical aids can vary in colour and shape and may include electronic options.
        </p>
      </div>

      <div id="sub-section-1-header-6">
        <h3>1.6 Pillar Obstacle</h3>

        <image-component tag="image" source="assets\section-1-safmc2025\figure_1_10_specifications_of_pillar_obstacles.png"
        subtitle="Figure 1.10: Specifications of Pillar Obstacles"></image-component>

        <p>
          Eight Pillar Obstacles will be presented in the Pillar Area. The Pillar Obstacles have the dimensions of 0.3 m diameter and 2 m height, inclusive of a weighted circular base of 0.5 m diameter and 0.15 m height. Figure 1.14 does not show the actual Pillar Obstacles used for the competition.
        </p>
      
        <p>
          Taking reference from SAFMC 2022, Figure 1.15 shows the Pillar Obstacles that may be used in SAFMC 2025. However, the competition will take place in a well-lit indoor venue.
          </p>

      </div>

      <div id="sub-section-1-header-7">
        <h3>1.7 SAFMC 2025 vs SAFMC 2024</h3>

        <comparison-safmc subtitle="Table 1.0: Comparison of Competition Rules for SAFMC 2024 and SAFMC 2025">
          <div id="comparison-safmc"></div>
        </comparison-safmc>

        <p>
          Table 1.0 shows an overview of the differences in the Competition Rules for SAFMC 2024 and SAFMC 2025.
        </p>
        <p>
          For SAFMC 2025, an Unknown Search Area is introduced, in which the layout of the Unknown Search Area will remain undisclosed throughout the Competition Day Mission. Additionally, the layout of the Known Search Area will only be disclosed on the Competition Day Mission. In contrast, for SAFMC 2024, the layout of the entire Arena was only disclosed on the Competition Day Mission.
          </p>
        
          <p>
          Furthermore, SAFMC 2025 introduces eight Pillar Obstacles, which are a new type of static obstacles within the Arena. Eight Victims Markers will be present, which includes both Regular Victims and Bonus Victims. Each type of Victim Markers offers different scoring opportunities. The Double-Rescue Victims are removed from this year’s competition.
          </p>
          
        <p>
          Additionally, a maximum of four Danger Zones is introduced for SAFMC 2025. Ten Navigation Aids are allowed within the Known Search Area and no Navigation Aids are allowed within the Unknown Search Area.
          </p>

      </div>
    </div>

    <br />
    <br />

      <div id="section-header-2" class="section" style="display: none;">
        <h2>2. Selected Drone Platform </h2>
          <p>
            Given the project’s scope, an off-the-shelf drone platform was used in this project as building custom drones is complex and impractical. The selection of the drone platform for autonomous search and rescue missions was based on size and weight, modularity, sensor capabilities, cost, and availability. The ideal platform should be ultra-lightweight to support scalability in swarm applications. It should also be highly modular in both hardware and software, featuring swappable parts for ease of maintenance and open-source software to provide flexibility in developing solutions. The drone should be equipped with sensor suites that enable localization, obstacle detection, and avoidance capabilities. 
            The drone platforms considered were DJI Tello, Bitcraze Crazyflie 2.1+, and DEXI Drone – Level III. The selection matrix for the drone development platform selection is in Appendix A.
          </p>
      <div id="sub-section-2-header-1">
        <h3>2.1 Hardware: BitCraze Crazyflie</h3>
        <p>
          The Bitcraze Crazyflie 2.1+ was selected as the development platform for this project due to its superior lightweight design, modularity, and extensive sensor compatibility. 
        </p>

        <image-component tag="image" source="assets\section-2-selected-drone-platform\figure_2_1_bitcraze_crazyflie.png"
        subtitle="Figure 2.1: Bitcraze Crazyflie 2.1+ Drone Development Platform"></image-component>
        <p>
          A key advantage of the Crazyflie is its open-source framework, which includes the Crazyflie firmware, the cflib Python library, and compatibility with ROS2 via the Crazyswarm2 package. The Crazyflie also supports onboard autonomy using the Crazyflie App Layer, allowing mission-specific algorithms to run directly on the drone without requiring continuous external communication.
        </p>

        <p>
          In terms of hardware modularity, Bitcraze has an extensive ecosystem, providing various expansion decks that enhances its sensing and navigation capabilities. In this project, we will work with Crazyflie equipped with the Flow Deck, Multi-ranger Deck and AI Deck. The Flow Deck contains Time-of-Flight (ToF) sensor for measuring distance to the ground and an optical flow sensor to measure velocity, enabling localization. The Multi-ranger Deck consists of five ToF sensors positioned to measure distances in the front, back, left, right, and up direction, enabling obstacle detection and avoidance. Finally, the AI Deck includes a monochrome camera (HM01B0), an onboard MCU chip (GAP8), and ESP32, which allows for onboard image processing along with Wi-Fi connectivity for real-time data transfer and remote communication.
        </p>
        
        <image-full tag="image" source="assets\section-2-selected-drone-platform\figure_2_2_expansion_decks.png"
        subtitle="Figure 2.2: Expansion Decks: (Left) AI Deck, (Middle) Flow Deck, (Right) Multi-ranger Deck"></image-full>
        <br><br>
        <image-full tag="image" source="assets\section-2-selected-drone-platform\figure_2_3_configuration_of_upgraded_crazyflie_with_expansion_decks.png"
        subtitle="Figure 2.3: Configuration of Upgraded Crazyflie with Expansion Decks"></image-full>
        <br><br>

      </div>

      <div id="sub-section-2-header-2">
        <h3>2.2 Drone Software and Development</h3>
        <p>
          Crazyflie runs on the Bitcraze Crazyflie firmware, which is written in C and is fully open source. It includes an app layer that allow users to add custom code directly to the Crazyflie, making it the entry point for implementing decentralized autonomous capabilities. The app layer contains a set of APIs such as the Deck API that allows scripts running onboard to access sensor data like Multi-ranger Deck’s distance data, odometry data from   the Flow Deck, etc. (Bitcraze, 2024)  
        </p>

        <p>
          For centralized solutions, the Crazyflie can be integrated with ROS2 using the Crazyswarm2 Python package. This enables high-level control for multi-drone coordination via cflib, Python library that facilitates communication and control through Crazyradio, a long-range open USB radio dongle. In addition, the Crazyswarm2 package also enable the Ground Control Station (GCS) to access Crazyflie sensor data through the various ROS2 topics.
          The development workstations are equipped with ROS2 Humble, running on Ubuntu 22.04 to support software development.
        </p>

      </div>
    </div>
   
    <br />
    <br />

      <div id="section-header-3" class="section" style="display: none;">
          <h2>3 Search Strategy</h2>
          <p>
            With the vastly different Arena layout this year, our mission strategy also must change accordingly. The main 
            areas of consideration are the search strategy to use, object detection methods and use of navigation aids. 
          </p>
          <image-component tag="image" source="./assets/section-3-mission-strategy/figure_3_1_comparison_search.png"
          subtitle="Figure 3.1: A Comparison between Mapped and Mapless Search Strategy"></image-component>

          <div id="sub-section-3-header-1">
              <h3>3.1 Search Strategy</h3>
              <p>
                With the introduction of an entirely new Arena which can be split into 3 main areas – namely the Known Search Area,
                Unknown Search Area and Pillar Area, there is a need to test and decide what search strategies to opt for. 
                </p>
            
              <p>
                Last year’s search strategy was an unmapped, decentralized strategy (differences between strategies will be elaborated on in section 4.1), 
                and it did work and were able to complete the search the fastest amongst the teams that participated last year.  
              </p>

              <p>
                However, they did not win the first place as their approach lacked novelty, and did not use the hardware available to 
                them to its fullest potential. Therefore, they lost marks in the team live presentation and eventually came in second.
              </p>
            
              <p>
              Hence, we will be exploring both mapped and unmapped strategies and possibly use a combination of them due to the variety 
              of obstacles present, to improve the overall efficiency and novelty of the search strategy employed.
              </p>
          </div>

          <div id="sub-section-3-header-2">
              <h3>3.2 Object Detection</h3>
              <p>
                The introduction of new obstacles does not only require a revamp of the search strategy, but also a revised approach on the 
                object detection methods. With the presence of an Unknown Search Area, Danger Zones and Pillar Obstacles, we will need to re-evalute our current 
                object detection method and explore other methods before finalising on the method that is best suited for our use case. 
              </p>    
          </div>

          <div id="sub-section-3-header-3">
              <h3>3.3 Navigation Aids</h3>
              <p>
                With the presence of new obstacles, the use of Navigation Aids to help us in our search of the Victims Markers varies significantly. 
                There are many more use cases for navigations aids this year, especially in more tricky areas like the Unknown Seach Area and the Pillar Area. 
              </p>

              <p>
                However, the number of Navigation Aids remain the same as last year, despite there being 3 distinct challenges unlike only 1 last year. 
                We will evaluate on the most effective way to use the navigation aids, as well as what kind of items are we using. We will then need to 
                test and decide the most effective way to use these Navigation Aids. 
              </p>    
          </div>

          <div id="sub-section-3-header-4">
              <h3>3.4 Key Areas of Development</h3>
              <p>
                Our goal is to complete the mission in the quickest time possible while using novel and superior methods for our mission. Therefore, we have 
                split the key areas of development into the 4 roles below.  
              </p>

              <scope-of-work subtitle="Table 2.0: Scope of Work">
                <div id="scope-of-work"></div>
              </scope-of-work>
      
              <p>
              Table 2.0 shows the designation of roles for the development of the various sub-systems.
              </p>

              <p>
                The search strategy sub team will be exploring 2 mapping strategies while enhancing the unmapped strategy used last year as we the mapped approach 
                is more difficult to implement and hence will be awarded more marks in the team presentation.  
              </p>

              <p>
                The object detection sub team will be improving on the object detection method used last year as it was inaccurate and slow. Exploration of new methods 
                such as object classification using neural networks will be done simultaneously.   
              </p>

              <p>
                The obstacle detection and avoidance sub team will investigate strategies used to detect and avoid the new obstacles present, which are the Pillar Obstacles.   
              </p>

              <p>
                The simulation sub team will investigate the use of simulation to simulate various search algorithms to improve testing efficiency.   
              </p>
          </div>

    </div>

    <br />
    <br />

      <div id="section-header-4" class="section" style="display: none;">
      <h2>4. Object Detection (Shu Hui)</h2>


    <image-component tag="image" source="./assets/section-4-obj-detection/figure_4_1_hardware.png"
    subtitle="Figure 4.1: Hardware for Object Detection"></image-component>
    

    <div id="sub-section-4-header-1">
      <h3>4.1 Object Selection</h3>

      <image-component tag="image" source="./assets/section-4-obj-detection/table_2_decision matrix.png"
      subtitle="Table 2.0 : Decision Matrix for Target and Danger Zone Selection "></image-component>

          <image-component tag="image" source="./assets/section-4-obj-detection/figure_4_2_objects.png"
    subtitle="Figure 4.2: Regular/Bonus Victims, Danger Markers and Navigation Aids"></image-component>

    </div>

    <div id="sub-section-4-header-2">
      <h3>4.2 Onboard Detection</h3>

      <comparison-image-processing subtitle="Table 3.0: Advantages between On-board Processing and Off-board Processing (Bitcraze, n.d.)">
        <div id="comparison-image-processing"></div>
      </comparison-image-processing>    
    
    </div>

    <div id="sub-section-4-header-3">
        <h3>4.3 Offboard Detection</h3>
    <image-component tag="image" source="./assets/section-4-obj-detection/figure_4_4_camera_mount_angles.png"
    subtitle="Figure 4.3: Camera Mount Angles"></image-component>

        <video-component 
            source="https://www.youtube.com/embed/No0juLGqdLo" 
            subtitle="Figure 4.3: Video of Object Detection for One Crazyflie">
        </video-component>

    </div>

    <div id="sub-section-4-header-4">
      <h3>4.4 Optimising Detection Distance for the Drone</h3>

    <image-component tag="image" source="./assets/section-4-obj-detection/figure_4_5_graph_distance_vs_speed.png"
    subtitle="Figure 4.5: Graph of Vertical Distance from AprilTag (cm) vs Speed (m/s)"></image-component>

    <image-component tag="image" source="./assets/section-4-obj-detection/figure_4_6_graph_distance_vs_height.png"
    subtitle="Figure 4.6: Graph of Vertical Distance from AprilTag (cm) vs Height (m)"></image-component>

    <image-component tag="image" source="./assets/section-4-obj-detection/figure_4_7_landing_distance.png"
    subtitle="Figure 4.7: Detection Distance With Delay Implemented"></image-component>

    <image-component tag="image" source="./assets/section-4-obj-detection/figure_4_8_original_vs_updated_image_streaming.png"
    subtitle="Figure 4.8: Original Image Streaming Firmware (Left)  and Updated Image streaming Firmware (Right)"></image-component>

    </div>

    <div id="sub-section-4-header-5">
      <h3>4.5 External System Optimisation</h3>

      <video-component 
      source="https://www.youtube.com/embed/3d6A9wGV5tY" 
      subtitle="Figure 4.9: Video of One Drone Successfully Reversing">
  </video-component>

  <video-component 
      source="https://www.youtube.com/embed/TYLihQFfpwo" 
      subtitle="Figure 4.10: Video Swarm Ignoring (Danger Zone)">
  </video-component>

  <video-component 
      source="https://www.youtube.com/embed/RThMP-MyErE" 
      subtitle="Figure 4.11: Video of Swarm Detection (Victim Marker)">
  </video-component>

    <image-component tag="image" source="./assets/section-4-obj-detection/figure_4_12_router.png"
    subtitle="Figure 4.12: Old Router Setup and Modified Router Setup"></image-component>

    </div>

    </div>
      
    <br />
    <br />

      <div id="section-header-5" class="section" style="display: none;">
          <h2>5. Known Search Area (Yan Yew)</h2>
            <p>
              The Known Search Area in the Playing Field presents a structured environment where positions of static obstacles like Inner Walls are known. This information can be leveraged to preplan drone paths, ensuring complete coverage of the Known Search Area. This knowledge of the layout complements well with a mapless search strategy. 
            </p>
            <p>
              Compared to a mapped approach, which relies on a complete map or Simultaneous Localization and Mapping (SLAM), a mapless approach is significantly less computationally demanding and simpler to implement. A mapped strategy requires substantial processing power for SLAM and adds complexity, as the maps generated by each drone in the swarm must be merged and transmitted back to the drones, often via a GCS, which introduces a single point of failure. While normally mapless strategy does not inherently guarantee full coverage, since in this case the obstacle layout in the Known Search Area is known, optimization of search strategy to maximize coverage is possible hence a mapless approach would be a better option.
            </p>
            <p>
              To ensure a robust and scalable strategy, a decentralized strategy is adopted, where each drone operates independently without relying on centralized communication. This is achieved by writing the writing the navigation and decision-making code in C and flashing it directly onto the Crazyflie firmware.
            </p>
            <p>
              This section details the implementation of decentralized Modified Swarm Bug Algorithm (MSBA). Additionally, this section discusses the use of simulation in optimizing the search algorithm parameters, and key features like multi-airways for collision avoidance, and reverse commands to define search boundaries.
            </p>
      <div id="sub-section-5-header-1">
        <h3>5.1 Selection of Search Algorithms</h3>
          
          <p>
            The decentralized mapless search algorithms considered were Parallel Sweep Search, MSBA, and Pre-planned Flight Paths. These algorithms were shortlisted because they do not require a map, rely on heuristic that can easily be implemented onboard of the drones to form a decentralized system, and can be implemented in a multi-agent system like a drone swarm.
          </p>
          <p>
            Parallel Sweep Search is a search strategy that is commonly used in the maritime industry in search and rescue mission. Using multiple ship vessels to search a large area when location of search target is unknown. The search algorithm involves making the drones move in parallel, evenly spaced lanes that are offset to one another. When encounter a wall, the drone will perform wall-following around the obstacle until it returns to its original planned path then resume the sweep search. 
          </p>

          <image-component tag="image" source="./assets/section-5-known-area/figure_5_1_parallel_sweep_search.png"
          subtitle="Figure 5.1: Desired Paths of Two Drones Performing Parallel Sweep Search"></image-component>

          <p>
            The MSBA is an adaptation of the Swarm Gradient Bug Algorithm (SGBA) developed by TU Delft. This algorithm follows an identical heuristic as bug algorithm where the drone would travel in a specific heading, then encountered an obstacle it performs wall-follow around it until its original heading is free of obstacle. This algorithm is explained in detail in Section 5.2. 
          </p>
          <p>
            The pre-planned flight path strategy involves programming a series of predefined movements for each drone before deployment, which is possible because of the environment being known. For example, as illustrated in Figure 5.2, if we want the drone to reach point X, the drone will be programmed to fly forward. When obstacle is detected by the front ToF sensor, the drone should turn right and continue forward until it detects another obstacle using the front ToF sensor.
          </p>

          <image-component tag="image" source="./assets/section-5-known-area/figure_5_2_pre_planned_flight_path.png"
          subtitle="Figure 5.2: Pre-planned flight path strategy: Diagram illustrating the drone’s movement from the start area to point X. "></image-component>
          <p>
            The decentralized mapless strategies shortlisted above are then evaluated using a weighted decision matrix. The main factors to consider were (1) search coverage, (2) adaptability, (3) exploration speed, and (4) implementation complexity. For each of these strategies, the search strategies are given a score out of 3 for how well it performs.
          </p>
          <p>
            Table 4.0: Evaluation of Parallel Sweep Search, Modified Swarm Bug Algorithm, and Pre-planned Flight Path Search Strategies
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/table_4_decision_matrix_search.png" subtitle=""></image-component>
          <p>
            Search coverage evaluates the ability of the algorithm to cover the entire search area. A higher coverage indicates a more effective exploration to search for victim markers in the Playing Field. This criterion is assigned the highest weight because the competition’s scoring criteria is based on the number of victim markers rescued. A higher coverage increases the likelihood for the swarm drone to locate these victim markers placed throughout the Playing Field. Parallel Sweep Search is given the highest score because theoretically with multiple drones offset to each other, the swarm will be able to cover the entire search Playing Field. MSBA and pre-planned flight path both can provide high search coverage but due to the heuristic, they won’t perform better than Parallel Sweep Search.
          </p>
          <p>
            Reliability concerns with the predictability, repeatability, and robustness of the strategies. High reliability is important because the competition only allows each team to perform two runs, so a reliable solution should be used to ensure consistent performance during the competition. Parallel Sweep Search is given the lowest score because it depends heavily on localization and precise pathing. Based on a drift test conducted on the flow deck, the uncertainty in the localization the optical flow sensor is ±10 %, which is not precise. MSBA is given the highest score because it depends on heuristic that utilizes the ToF distance sensors, which are highly precise. The pre-planned flight path is given a similar high score of 3 for a similar reason.
          </p>
          <p>
            Adaptability is defined as the ability for the algorithm to maintain consistent search coverage performance in environments with different obstacle sizes. Although the layout of the obstacles in the Known Search Area is known, the dimensions of these obstacles are not. An algorithm that is highly adaptable should be able to maintain consistent behaviour, ensuring reliable search coverage across various obstacle configurations. MSBA is the most adaptable because it allows the drones to react to obstacles and adjust their behaviour accordingly. Parallel Sweep Search can handle obstacle with wall-following behaviour. However, it can be prone to failure if the dimensions of certain walls exceed the range considered during the planning phase. The pre-planned flight path has the lowest adaptability because the flight paths must be tailored to specific Playing Field configurations.
          </p>
          <p>
            Exploration speed is the amount of time it would require for the swarm drone to search a fixed area. This criterion is given the lowest weight because the runtime of the drones is not a scoring criterion but instead used as a tiebreaker. The Parallel Sweep Search is the slowest because of the sweep pattern that drones need to trace. MSBA and the pre-planned strategies are given the highest score of 3 because the drones follow paths that generally lead from the start area to the end of the Playing Field without the need for backtracking.
          </p>
          <p>
            Based on decision matrix evaluation above, MSBA stands out as the most well-rounded search strategy. MSBA excels in reliability, adaptability, and exploration speed, making it the most suitable approach for the swarm drone search mission. Its ability to respond to obstacles dynamically and adjust its behaviour accordingly allows it to maintain consistent performance across different environments, particularly in the Known Search Area with its unpredictable obstacle dimensions.
          </p>
        </div>

      <div id="sub-section-5-header-2">
      <h3>5.2 Modified Swarm Bug Algorithm</h3>
          <p>
            MSBA is a heuristic algorithm governed by a few simple rule-based behaviour as illustrated in Figure 5.3. After take-off, the drone rotates to its preferred heading and then moves forward in that direction. Upon detecting an obstacle, it initiates wall-following until its preferred heading is clear of obstacles.
          </p>
          <p>
            To prevent the Crazyflie from getting trapped in an indefinite loop, a loop detection mechanism is implemented. This mechanism modifies the preferred heading when the drone is detected to be stuck. When the Crazyflie encounters an obstacle and begins wall-following, it records the hit point using odometry data from the Flow Deck. If the drone moves toward the same hit point again, the loop detection mechanism is triggered, adjusting the navigation path to break the loop. 
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/figure_5_3_MSBA.png"
          subtitle="Figure 5.3: Visualization of MSBA"></image-component>
          <p>
            The performance of MSBA is determined by the coverage, speed, and reliability of the swarm drones. Ideally, the swarm would cover all the Known Search Area as fast as possible, and reliably by having reproducible results and zero collisions among the drones. The performance greatly relies on key parameters such as flight speed, altitude, wall-following direction, corresponding wall-following distance. Wall-following direction refers to the side of the wall that the drones use as a guide while navigating. Wall-following direction refers to the relative position of the wall that a drone maintains while navigating. A left wall-following direction means the drone keeps the wall to its left as it moves, while a right wall-following direction means the drone keeps the wall to its right.
          </p>
      </div>

      <div id="sub-section-5-header-3">
        <h3>5.3 Initial Proposal Strategy Using MSBA</h3>
          <p>
            The team has allocated a total of 10 drones to search the Known Search Area. To obtain the optimal parameters, the ideal paths of the 10 drones to maximize coverage are first planned in accordance with the heuristic of the algorithm. Then the parameters required to achieve the corresponding flight paths are then determined by working backwards. 
          </p>          
          <p>
            The strategy to perform search in the Known Search Area is illustrated in Figure 5.4. It involves deploying the drones on the left side of the Playing Field, ensuring they reach designated dispersion points—Point A, Point B, and Point C, which the drones will then fan out in their respective preferred headings. Each dispersion point is assigned three drones. To guide the drones to their respective dispersion points, they will follow a wall-following manoeuvre around Wall 1, Wall 2, and Wall 3 before dispersing into the search area. 
          </p>
          <p>
            The flight altitude of all drones is set to 0.3 m because real-life test flight at that height provided great flight stability. The speed of drones is set to 0.4 m/s as it is the optimal speed for stable flight performance after performing real-life testing which will be explained in later section in Section 5.6. This speed also ensures reliable AprilTag detection as tested by the Object Detection system (Section 4.4).
          </p>
        <image-component tag="image" source="./assets/section-5-known-area/figure_5_4_maximise_coverage.png"
          subtitle="Figure 5.4: Strategy to maximise search coverage using 9 drones running MSBA"></image-component>
          <p>
            For intra-drone collision avoidance strategy to prevent drone-to-drone collisions, a two-lane method was implemented. Depending on the direction of wall-following, the drones would maintain different distance to walls to create two separate lanes. Extensive real-world testing a small-scale Playing Field, along with simulations, confirmed the reliability of this strategy, provided that the drones are correctly positioned at the starting area The optimal wall distances were determined to be 0.6 m for drones performing left wall-following and 1.2 m for those performing right wall-following, as illustrated in Figure 5.5 below.
          </p>
          <p>
            Additionally, the loop detection transformation angle was set to be 90 ° instead of the 180 ° proposed in the original SGBA to prevent drones from travelling straight back to the starting area. The transformation angles depend on the drones' wall-following direction and follow the right-hand rule convention: drones assigned to right wall-following adjust their preferred heading by +90 °, while those following the left wall adjust by -90 °.
          </p>
          <p>
            Since all the drones must take off within two waves, to ensure the drones reach their respective dispersion points safely without collision, drones belong to Point B will first take off, followed by drones that travel to Point A and Point C. This configuration will also prevent drone collisions by ensuring Point B drones to be in the forefront, followed by Point C and Point A drones that will be unlikely to collide with one another as they travel in opposite directions.
          </p>
          <p>
            The drone configurations in the Start Area to guide the 3 separate drone groups to dispersion points A, B, C is shown below in Figure 5.5. Each drone is also assigned wall-following direction of either left or right. Drone 1, 2, 3 will first take off and travel to Point A, then followed by Drone 4, 5, 6 to Point C and Drone 7, 8, 9 to Point A. The drones in each group are arranged in a "V" formation. Reason being because based on real-life swarm drone testing, maintaining a clear LOS in the forward direction is crucial, especially during take-off. If a drone detects another drone directly in front of it, it will automatically initiate wall-following mode, potentially disrupting the planned dispersion sequence. 
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/figure_5_5_initial_configuration.png"
          subtitle="Figure 5.5: Initial configurations of drones in the start area"></image-component>
      </div>

      <div id="sub-section-5-header-4">
        <h3>5.4 Simulation to Evaluate Search Strategy</h3>
          <p>
            To validate, evaluate and further optimize the above proposed strategy, extensive testing is required. Performing small scale tests by recreating subsections of the Playing Field is not possible because it is difficult to predict the state of the drones at the boundaries of the subsections. Full-scale is also not feasible because of the space constraints at Studio 1. Therefore, a simulation environment was created. 
          </p>
          <p>
            Beyond addressing space limitations, simulation enables rapid troubleshooting of search algorithms and fine-tuning of parameters without the need to physically redeploy the code onto the drones every time a change is made. Webots was used as simulator because it allows individual robot in the environment to execute is own C code, which mirrors the actual implementation of the decentralized search strategy using MSBA. A key consideration in developing this simulation environment was ensuring that the same code deployed onto the drone firmware could be tested within the simulation.
          </p>
          <p>
            To create a decentralized system, the MSBA scripts are all running onboard of Crazyflie. The scripts are all compiled on the development workspace before flashing onto the drone using Crazyradio. This will write the scripts within the app layer in the Crazyflie firmware. When the drone starts up, the firmware will execute the scripts inside the app layer, which then have access to all the deck sensor APIs, enabling the drones to operate autonomously without the need for centralized control.
          </p>

          <image-component tag="image" source="./assets/section-5-known-area/figure_5_6_firmware_onboard.png"
          subtitle="Figure 5.6: Architecture diagram of firmware on board of real Crazyflie"></image-component>
          <p>
            While Webots provides an excellent platform for simulating robots running onboard scripts, it does not support the Crazyflie firmware, or the identical Deck API used in the actual Crazyflie hardware. As a result, to integrate MSBA with the Webots simulation, an interface is required to bridge the gap between MSBA and the simulation environment. This interface allows the MSBA to access the necessary sensor readings, such as distance data from virtual sensors, and provides a means for the Webots robot to receive output from the MSBA, ensuring that the drone's behaviour in the simulation mirrors that of the actual Crazyflie system.
          </p>
          <p>
            The full Webots repository that contains the simulation environment and controller code can be found here https://github.com/CDE-4301-ASI-401/Webots_CF2.
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/figure_5_7_firmware_webots.png"
          subtitle="Figure 5.7: Architecture diagram of simulated Crazyflie in Webots"></image-component>
          <p>
            The competition search environment was first recreated in Webots as shown in Figure 5.8, with the static obstacles being placed according to the Playing Field layout illustrated in the competition challenge booklet while conforming to the minimum distance. Each box represents a 1 m by 1 m area. <i>Note that the orientation of the top-down view differs from the previous figures. The view in this figure is rotated clockwise by 90 °</i>.
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/figure_5_8_webots_simulation_environment.png"
          subtitle="Figure 5.8: Webots Simulation Environment"></image-component>
          
          <p>
            The performance of the search strategy was then evaluated by simulating the drones in different Playing Field configurations. The drone paths after 4 minutes of simulation are plotted and compared using the drones position data stored in csv files and Matplotlib. The percentage of search coverage is also determined by counting the box which the swarm drone’s paths crossed in the Known Search Area overlayed in Figure 5.5. 
          </p>
          <p>
            In all the configurations tested, the drone swarm was able to cover most of the Known Search Area collectively, consistently achieving a search coverage above 80%. However, there are a few blind spots that would be miss by the drones. Notably, the area in corners. Figure 5.9 shows the results from 3 of the simulations performed, as well as the blind spots. In addition, in certain scenarios, some drones will travel into the Pillar Area, which is undesired.
          </p>
          <p>
            After multiple simulations, the two-lanes collision avoidance strategy proved reliable, as no collisions occurred beyond the initial take-off phase where drones fly to their respective dispersion points. Drone-to-drone collisions were only observed between drones in the same group, primarily due to insufficient spacing between drones in the Start Area.
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/figure_5_9_Webots_Simulation.png"
          subtitle="Figure 5.9: Simulated paths of drones performing MSBA in a full-scale arena after 4 minutes"></image-component>

          
      </div>

      <div id="sub-section-5-header-5">
        <h3>5.5 Improvements to MSBA</h3>
          <p>
            To address blind spots in the corners of walls, two wall-following (WF) drones will be deployed to cover these areas, as identified in the simulation. To prevent these WF drones from interfering with the paths of the MSBA drones, these WF drones will be fly at a higher altitude of 0.55 m, 0.25 m higher than the altitude of MSBA drones. At this altitude, the effect of downwash on the MSBA drones flying below the WF drones is minimal and has no significant impact on image detection as tested (Section 4.4). 
          </p>
          <p>
            A total of ten drones are assigned to search the Known Search Area. Since only nine drones were initially used to test the MSBA search strategy, an additional tenth drone will be introduced to perform WF along the outer perimeter of the Playing Field, while drone number nine will be reassigned to WF as well. These drones will maintain a wall-following distance of 0.5 m to handle cases where object markers are placed in the corners. With the addition of a new drone and the reassignment of one drone to WF, the search coverage increased to over 90 %, calculated using the same method described previously.
          </p>
          <p>
            To address the scenario where drones cross into the Pillar Area like the fourth figure in Figure 5.9, a reverse function was implemented in MSBA to enable the drones to perform 180 degrees turn and continue searching within the Known Search Area. To facilitate this mechanism, two April Tag Navigation Aids will be placed at the border between Known Search Area and Pillar Area. When an MSBA drone in the Known Search Area detects them, the Mission Planner will broadcast a reverse command packet to the detecting drone. Upon receiving this packet, the drone will adjust its preferred heading by 180 degrees, ensuring it remains within the designated search area.
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/figure_5_10.png"
          subtitle="Figure 5.10: Placements of two Navigation Aids at the border between Known Search Area and Pillar Area"></image-component>
      </div>

      <div id="sub-section-5-header-6">
        <h3>5.6 Real Life Testing</h3>
          <p>
            To validate the MSBA implementation and further optimize flight parameters, a series of real-world tests were conducted in three different environments, where 1 m by 1 m cardboards are used to create wall obstacles:
          </p>
          <ol>
            <li>Small-scale tests in the studio</li>
            <li>Medium-scale tests in a seminar room at E7 </li>
            <li>Full-scale tests in RC4 Hall  </li>
          </ol>
          <p>
            Initially, most tests were small-scale tests conducted in E2A Studio 1 to optimize individual drone flight stability by tuning flight parameters such as wall-following distance, flight speed, and altitude. Prior to creating the simulation environment, these small-scale tests provided the optimum flight parameters for the MSBA drones which was later used in the simulation.  The small-scale test also enabled the reverse function to be tested by manually issuing the reverse command packet before integrating it with the Mission Planner system.
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/figure_5_11_small_scale_test.png"
          subtitle="Figure 5.11: Small-scale test environment in E2A Studio 1"></image-component>
          <p>
            A key issue observed when testing the WF drones was that they had difficulty turning around thin wall edges of the L-shaped free-floating wall in the Known Search Area. When turning around these edges, the drones would lose track of the wall edges due to the narrow field of view of the side ToF sensor. To mitigate this, 2 wall guards are used as Navigation Aids. These Navigation Aids are created by creating a trifold using a corrugated board and are used by slotting them around the wall edges of the L-shaped wall. By effectively increasing the wall-thickness around the wall edges, the WF performance is significantly improved.
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/figure_5_12_wall_guard.png"
          subtitle="Figure 5.12: Wall-guard navigation aid used to increase thickness of wall edges"></image-component>
          <p>
            Subsequently, medium-scale tests were performed in E7 seminar rooms. With a larger space, subsections of the Known Search Area were recreated to test the behaviour of swarm clusters (around 3 to 5 drones). These tests validated the Webots simulation, as the drones’ behaviour and paths closely matched those generated in the simulation. However, they also revealed challenges unique to executing the MSBA search strategy in the real-world.
          </p>
          <p>
            The MSBA drones’ paths were highly dependent on their initial configuration in the Start Area. During the first few tests, the MSBA drones often deviated from the intended path due to inaccurate initial orientation when placed at the Start Area. In some cases, this resulted in the drones failing to reach reaching the dispersion zone in the Known Search Area, as they miss the walls that would have guided them correctly. Additionally, when drones were placed too close to one another, they either exhibited erratic after detecting the drone in front as a wall obstacle or, in worse the worst case, collided with the drones ahead.
          </p>
          <p>
            Unlike in simulation, where drone placements are accurate and precise, the initial medium-scale tests revealed the significant impact of human error on overall search coverage. To mitigate deviations in the initial preferred heading of MSBA drones, laser pointers were used to align them correctly in the Start Area. Furthermore, to prevent drones from being too close to one another, they were spaced farther apart to fully utilize the large Start Area.
          </p>
          <p>
            Finally, full-scale tests were conducted in RC4. The 20m-by-20m competition Playing Field was recreated to evaluate the performance of the entire swarm drone Initially, the drones exhibited poor localization, drifting, sudden accelerations, and jerky movements due to the venue’s reflective flooring. This issue is discussed in detail in Section 9. To mitigate this problem, all drones were flown at a higher altitude—MSBA drones were raised from 0.3m to 0.5m, while WF drones were increased from 0.55m to 0.75m. During these tests, the drones closely followed the same paths as their simulated counterparts in Webots.
          </p>
          <image-component tag="image" source="./assets/section-5-known-area/figure_5_13_full-scale_test_Known_Area.png"
          subtitle="Figure 5.13: Full-scale testing of Known Search Area drones "></image-component>
      </div>

      <div id="sub-section-5-header-7">
        <h3>5.7 Final MSBA Configurations</h3>
        <p>
          After conducting the series of real-world tests, the set of flight parameters for Known Search Area drones performing MSBA and wall-following were determined. 
        </p>
        <p>
          Table 5.0. Key parameters of drones performing MSBA and WF in the Search Area during actual competition
        </p>
        <image-component tag="image" source="./assets/section-5-known-area/table_5_known_config.png" subtitle=""></image-component>
        <br><br> 
        <image-component tag="image" source="./assets/section-5-known-area/figure_5_14_final_known_start_area_config.png"
          subtitle="Figure 5.14. Drone position and orientation at the Start Area to execute the MSBA search strategy"></image-component>
        <p>
          During the actual competition, three regular victims were placed within the Known Search Area for rescue. It should be noted that the placement of Victim and Danger Markers varied between Run 1 and Run 2. The take-off sequence and navigation to the dispersion points worked as intended. However, further drone behaviour could not be directly observed as the competition Playing Field was off-limits during the mission runs. The final results for the Known Search Area are outlined in Table 6.0.
        </p>
        <p>
          Table 6.0. Number of victims rescued in the Known Area
        </p>
        <image-component tag="image" source="./assets/section-5-known-area/table_6_Known_area_rescues.png" subtitle=""></image-component>
 
        <p>
          In the first run, two out of three regular victims were successfully rescued. However, before the run began, the wall-guard Navigation Aid, which was designed to increase the thickness of the wall edges, was mistakenly left out and not placed around the L-shaped wall in the Known Search Area. This issue was rectified before the second run, and during this run, all of the regular victims were rescued. However, since the victim placements differed between runs, it was not conclusive whether the victim missed in Run 1 was located near the L-shaped wall. Without the Navigation Aid in place, the wall-following drone was unable to reach it.
        </p>
      </div>

    </div>

      <br />
      <br />

      <div id="section-header-6" class="section" style="display: none;">
        <h2>6. Unknown Search Area (Yan Yew)</h2>
          <p>
            The Unknown Search Area is an 8 m by 8 m area situated in the centre of the Playing Field accessible through two entrances/exits to the right and at the top of the area. Unlike the Known Search Area and Pillar Areas that are easily accessible after crossing the Start Area, drones searching the Unknown Search Area need to first reach either entrances to the Unknown Search Area, then start searching the areas. 
          </p>
          <p>
            A mapped approach was initially explored to ensure full coverage of the Unknown Search Area. This would require drones to perform SLAM to generate occupancy grids of the environment, enabling the use of search strategies such as frontier-based exploration, where all drones assigned to the Unknown Search Area would simultaneously map and search, or path planning algorithms, where a subset of drones focuses on mapping and marking victim locations while the rest are dedicated to rescue operations. In this approach, once victims are detected, a path planning algorithm would determine the optimal route and direct the rescue drones accordingly.
          </p>
          <p>
            This section documents the feasibility tests conducted on the mapped approach and the challenges encountered, ultimately leading to the adoption of MSBA for searching the Unknown Search Area. Initial experiments involved performing SLAM using the multi-ranger deck onboard the Crazyflie to generate occupancy grids. However, due to sensor range limitation and poor localization, SLAM proved unreliable for real-time mapping and navigation. These constraints made frontier-based exploration and path planning strategies impractical. Given these limitations, the MSBA originally designed for the Known Search Area was adapted for the Unknown Search Area drones as well. 
          </p>
  
        <div id="sub-section-6-header-1">
          <h3>6.1  Feasibility Resting of Mapping Hardware</h3>
            <p>
              A centralized approach using ROS2 was chosen to perform SLAM due to the limited computation resources available on the STM onboard the Crazyflie. This approach provided scalability and ease of implementation, as it can be easily integrated with the Mission Planner, which also operates on ROS2. This approach would also allow us to leverage on existing tools and libraries for SLAM. To implement SLAM on a swarm of drones, each individual drone needs to produce an accurate map. These individual occupancy maps can then be merged to create a single, complete map.
            </p>
            <p>
              The performance of SLAM using a single Crazyflie was first tested using the Crazyflie ROS2 Multiranger package. This multi-ranger package uses the Crazyswarm2 package to collect sensor data from the Crazyflie via the Crazyradio, which is then used to construct an occupancy map. 
            </p>
            <p>
              For testing, a 4m by 5m enclosed space was set up in the E2A Studio. A single Crazyflie was deployed to perform SLAM while following the walls within the enclosed space. Upon completing a full loop and returning to its starting position, the drone was terminated, and the resulting map was evaluated.
            </p>
          <image-component tag="image" source="./assets/section-6-unknown-area/figure_6_1_enclosed_space.png"
          subtitle="Figure 6.1: Enclosed space (4m by 5m) set up to test Crazyflie SLAM performance"></image-component>
          <p>
            During the initial tests, the maps produced by the drone was poor that did not remotely match the ground truth. In one of the runs, it was observed that when the drone performed SLAM, it was leaving an “occupied” trail in Figure 6.2. Upon inspection, it was discovered that the ToF sensors on the multi-ranger deck can be obstructed by the AI deck located below it, as shown in Figure 6.2. After lifting the multi-ranger up to ensure the ToF sensors are unobstructed and cleaning the ToF sensors, this single Crazyflie was able to consistently produce accurate map.
          </p>
          <image-component tag="image" source="./assets/section-6-unknown-area/figure_6_2_occupacy_map.png"
          subtitle="Figure 6.2: Occupancy map produced by single Crazyflie when its back TOF sensor was obstructed"></image-component>
          <br><br>
          <image-component tag="image" source="./assets/section-6-unknown-area/figure_6_3_obstructed_tof.png"
          subtitle="Figure 6.3: Obstructed TOF sensor on Crazyflie’s Mult-Ranger deck"></image-component>
          <br><br>
          <image-component tag="image" source="./assets/section-6-unknown-area/figure_6_4_SLAM_Single_Crazyflie.png"
          subtitle="Figure 6.4: Occupancy map produced by Crazyflie performing wall-following"></image-component>
          <p>
            With a single Crazyflie producing a reliable SLAM map, the next step was to evaluate multi-drone SLAM by merging occupancy maps from multiple Crazyflies. To achieve this, the ROS2 Merge Map package was integrated into the system. This ROS2 node subscribes to multiple map topics and publishes a single merged occupancy map, allowing the GCS to construct a complete map of the environment. The final implementation can be found in Github repository.
          </p>
          <p>
            To test the multi-drone SLAM and map merging implementation, two Crazyflies were deployed in a 4 m by 4m enclosed space, performing SLAM while wall-following in opposite directions. Initially, after both drones completed their first loop, the merged map was accurate and closely matched the actual environment. However, as the drones continued to complete additional loops, the mapped environment began to drift over time, leading to misalignment in the final merged map (Figure 6.X). This issue was attributed to drift in the individual Crazyflie’s optical flow sensor readings. As the drones continued wall-following around the enclosed space, positional errors accumulated significantly, causing increasing discrepancies between the mapped and actual environments.
          </p>
          <image-component tag="image" source="./assets/section-6-unknown-area/figure_6_5_Two_Crazyflie_SLAM_environment.png"
          subtitle="Figure 6.5:Test environment to evaluate the performance of Crazyflie SLAM using onboard multi-ranger deck"></image-component>
          <br><br>
          <image-component tag="image" source="./assets/section-6-unknown-area/figure_6_6_merge_map.png"
          subtitle="Figure 6.6: Merge map generated by two drones performing wall-following around enclosed space in Figure 6.5 "></image-component>
          <p>
            To mitigate map drift in multi-drone SLAM, proper loop closure detection must be implemented. Loop closure detection works by extracting features from the current sensor data and comparing them with previous sensor data. If a match is found, a loop closure constraint is placed in the SLAM map, reducing cumulative error (Nashed, 2020). 
          </p>
          <p>
            However, implementing loop closure detection requires a large amount of data to overcome inherent sensor noise. This is not feasible with the ToF sensors on the Crazyflie due to their narrow field of view. Sparse sensing is a niche research area in SLAM that aims to improve performance using limited sensor data. One study suggests leveraging fast convex optimization techniques to implement loop closure detection (Latif et al., 2017). However, without any publication on actual implementation, integration such method to Crazyflie will require too much time and resources. 
          </p>
          <p>
            ETH-PBL recently developed Nano Swarm Mapping, a decentralized solution tailors for nano drones like the Crazyflie. Unlike a centralized SLAM solution which relies on a GCS to process sensor data and construct maps, this solution enables each drone to independently perform scanning of environment onboard using ToF sensors, then broadcasting the scans and poses to the “main drone”, a drone within the swarm that is assigned to collect the scan data, perform SLAM finally broadcasting the results back to the swarm. To mitigate the effect of drifts, the researchers designed a modified multi-ranger deck which features ToF sensors with wider FOV and was able to implement loop closure detection (Friess et al., 2024). Despite its advantages, adopting this solution was not feasible due to the requirement of modified multi-ranger that was not readily accessible.
          </p>
        </div>
  
        <div id="sub-section-6-header-2">
          <h3>6.2 Feasibility Testing of Mapping Software</h3>
        
        </div>


        <div id="sub-section-6-header-3">
          <p>
            Due to the poor performance of SLAM using multiple drones, it was decided to implement MSBA for the Unknown Search Area drones to ensure sufficient tests can be conducted before the competition. Six drones are assigned to the Unknown Search Area (drone number 4, 5, 6, 7, 8, 9), the three even-numbered drones (4, 6, and 8) will enter from the top opening of the Unknown Search Area while the remaining odd-numbered drones (5, 7, and 9) will enter from the right opening, this will help maximising search coverage as the drones will be more spread out, and to tackle the possibility of the Unknown Search Area consisting two subsections that are only accessible through the two separate openings.
          </p>
          <div id="sub-section-6-header-3-header-1">
            <h4>6.3.1 Drone Guidance to the Unknown Area</h4>
            <p>
              To get to the openings to the right and top of the Unknown Search Area, the drone will travel through the passageway between the Unknown Search Area right outer wall and the pillars. The right opening will be referred to as Entrance 1, and the top opening will be referred to as Entrance 2. The 3 drones that will enter from Entrance 1 belong to Group 1 and the other 3 drones that enter from Entrance 2 belong to Group 2. 
            </p>
            <image-component tag="image" source="./assets/section-6-unknown-area/figure_6_6_desired_paths.png"
            subtitle="Figure 6.7: Desired paths of Group 1 and Group 2 drones to navigate from Start Area to the Unknown Area"></image-component>
            <p>
              The desired paths of Group 1 and Group 2 drones are first considered from Start Area to the respecting Unknown Search Area openings as illustrated in Figure 6.1 above. There are 3 waypoints along the path from the Start Area to Entrance 2 (orange arrow in Figure 6.1) where key events take place. When a drone reaches point A, it should continue moving forward if it belongs to 2, otherwise turn left into Entrance 1 and begin searching the Unknown Search Area. At point B, the drones should turn left and continue moving forward. At point C, the drones should turn left into the Unknown Search Area and start searching for victim markers.
            </p>
            <p>
              To achieve the desired paths, Navigation Aids will be placed on point A, B, and B, which will be referred to Tag A, Tag B, and Tag C respectively. Whenever these tags are seen by the drones, a radio command unique to the Navigation Aid will be issued to that drone. At the Start Area, all the Unknown Search Area drones will be lined up with point A and B being straight forward to them. 
            </p>
            <p>
              According to Figure 6.7, there are three unique possible motions that the drones would perform to enter the Unknown Search Area, namely (1) Continue straight forward, (2) Turn left, then continue straight forward, and (3) Turn left, move forward, and begin search. The pseudocode is shown in Algorithm 1, which is implemented in SGBA.c. 
            </p>
            <image-component tag="image" source="./assets/section-6-unknown-area/Algorithm_1.png"
            subtitle=""></image-component>
            <p>
              Since in Mission Planner there is only an only a one-to-one mapping of radio command to Navigation Aid. The logic to initiate the correct motion when received a radio command needs to be handled by the drone. For example, when a Group 1 drone received a radio command that corresponds to Tag A, it needs to initiate motion (3) Turn left, move forward, and begin search. Whereas a Group 2 drone receiving the same radio command should initiate motion (1) Continue straight forward. The pseudocode is included in Algorithm 2, which is implemented in state_machine.c.
            </p>
            <image-component tag="image" source="./assets/section-6-unknown-area/Algorithm_2.png"
            subtitle=""></image-component>
          </div>

          <div id="sub-section-6-header-2-header-2">
            <h4>6.3.2 MSBA for Searching the Unknown Area</h4>
              <p>
                Like the MSBA drones in the Known Search Area, these six Unknown Search Area drones have the same set of parameters to be optimized. Without knowledge of the obstacle layout in the area, the six drones will be evenly distributed to maximize search coverage, as shown in Figure 6.8. The preferred angles for each drone are relative to the forward direction, using the right-hand convention.
              </p>
              <image-component tag="image" source="./assets/section-6-unknown-area/figure_6_8_unknown_preferred_directions.png"
            subtitle="Figure 6.8: Preferred direction of MSBA drones after entering Unknown Area"></image-component>
              <p>
                To ensure the drones remain within the Unknown Search Area, Navigation Aids placed at the Unknown Search Area openings will be used to guide them. When a drone detects these Navigation Aids, the GCS will issue the corresponding radio command packet to the drone. Once the drones have entered the Unknown Search Area and are on a path to exit, they will again detect these Navigation Aids. Upon receiving the radio command packet from the GCS, the drones' preferred direction will be adjusted to keep them within the boundaries of the Unknown Search Area. The optimal position of Navigation Aids after extensive real-world testing are shown in Figure 6.8.
              </p>
              <image-component tag="image" source="./assets/section-6-unknown-area/Algorithm_3.png"
            subtitle=""></image-component>
            <p>
              Real-world testing with various transformation values revealed that a 135-degree transformation is the most optimal. While changing the preferred heading by 180 degrees would be the most effective way to keep the drones within the Unknown Search Area, it would not improve search coverage, as the drone would simply retrace its path in the opposite direction. A 90-degree transformation is not used, as it can cause the drone to exit the Unknown Search Area when approached at certain angles.
            </p>
            <p>
              The Unknown Search Area drones will adapt a similar intra-drone collision avoidance strategy as the Known Search Area drones, by flying the two groups of drones at different distance to wall and altitude. Group 1 drones will fly at 0.75 m, while group 2 drones will fly at 0.5 m. Due to the absence of wall-following drones covering area in wall corners, the drones will fly slightly closer to the wall compared to the MSBA drones in the Known Search Area. Group 1 drones (5, 7, 9) will perform left wall-following 0.4 m from the wall, group 2 drones (4, 6, 8) will perform right wall-following 1.0 m from the wall. All the drones will fly with the same maximum speed of 0.4 m/s.
            </p>
            <p>
              Table 7.0. MSBA parameters of Unknown Search Area drones
            </p>
            <image-component tag="image" source="./assets/section-6-unknown-area/table_7_unknown_final_msba_parameters.png"
            subtitle=""></image-component>
            <p>
              The Unknown Search Area MSBA drones will be lined up in the Start Area in the order of 4, 6, 8, 5, 7, 9. To mitigate the risk of collisions during take-off, the drones will be spaced equally apart, with both groups of drones taking off in separate wave. Group 2 drones (4, 6 ,8) will take off in the first wave to enter the top opening of Unknown Search Area, whilst the group 1 drones (5, 7, 9) will take off in the second wave, entering the Unknown Search Area from the right opening. 
            </p>
            <image-component tag="image" source="./assets/section-6-unknown-area/figure_6_9_unknown_start_config.png"
            subtitle="Figure 6.9: Configurations of Unknown Search Area drones in Start Area"></image-component>
          </div>
        </div>
  

        <div id="sub-section-6-header-4">
          <h3>6.4 Real-World Testing</h3>
          <p>
            Real-world testing is a critical phase in validating the effectiveness of the search strategy, ensuring that the drones can perform as expected in a variety of conditions. Small, medium and full-scale tests were conducted throughout the development process to ensure the functionalities work as intended.
          </p>
          <p>
            Firstly, small-scale tests were conducted in E2A Studio 1 to optimize the MSBA parameters such as wall distance during wall-following. The algorithm to guide drones into the Unknown Search Area was also extensively tested by manually issuing radio command to the drones. 
          </p>
          <p>
            After integration with Mission Planner, the autonomous navigation of two drones to the Unknown Search Area could be tested. This enabled the optimization of drone orientation in the Start Area. It is crucial to ensure the drones can detect the Navigation Aids and reach the correct opening. In the first few tests, the drones were often mis-orientation, which created paths that deviated away from the navigation, resulting in the Unknown Search Area drones crossing into the Pillar Area. 
          </p>
          <p>
            Then, medium-scale tests were performed in E7 seminar room. With a larger space, two-third of the Unknown Search Area could be constructed, and all six Unknown Search Area drones could be tested simultaneously. However, due to some drones unable to stream images, a maximum of four drones was tested simultaneously across all the medium-scale tests. With a larger swarm drone, the tests revealed the weakness of this strategy – reliance on image streaming. Visual feedback is essential in guiding the drones into the Unknown Search Area and keeping them within the Unknown Search Area. During the tests, the Wi-Fi connection of the drones was intermittent, leading to windows of time without image feedback. When these periods overlap with drones approaching the Navigation Aid, this will result in them missing the entrances and entering the Known Search Area at the top of the Playing Field. This is problematic because it means the drones will not be able to search the Unknown Search Area, and in the worst case, create risk of collisions with the Known Search Area drones. 
          </p>
          <p>
            Understanding the significance of reliable Wi-Fi connectivity in executing the search strategy for Unknown Search Area, the team worked closely together to optimize the Wi-Fi network for the swarm drone and was able to mitigate the intermittent Wi-Fi connectivity. This was explained in detail in Section 4.5.
          </p>
          <p>
            Finally, full-scale tests were performed with the other subsystems in a competition-scale Playing Field. All six drones assigned to search the Unknown Area was tested. Through these tests, the positions of the navigation aids were optimized to guide the drones to the entrances while ensuring them to be detected to prevent the drones from exiting the area.  
          </p>
          <p>
            During the competition, one bonus victim was placed in the Unknown Search Area. The position of the bonus victim changes across the two runs. At the end, we were unable to rescue the one bonus victim in both runs.
          </p>
          <p>
            Table 8.0. Number of victims rescued in the Unknown Area
          </p>
          <image-component tag="image" source="./assets/section-6-unknown-area/table_8_unknown_results.png"
            subtitle=""></image-component>
          <p>
            In the first run, only one of the six MSBA drones successfully entered the Unknown Search Area through the top opening. During setup, one drone experienced issues streaming images back to the GCS and was retired before the run. At take-off, another drone failed to lift off. Of the four remaining drones that took off, two drifted significantly, leading to a mid-air collision. Among the two drones that remained airborne, one successfully entered the Unknown Area through the top opening, while the other deviated from the navigation tag at the right opening and crossed into the Pillar Area and Known Area.
          </p>
          <p>
            For the second run, to mitigate drifting during take-off, the extra April Tags brought to the competition were used as launch platforms by placing the drones on top of the tags. While this method had been used by the previous team, our own testing showed it had negligible impact on take-off performance. The second run deployed only four out of six drones: the same drone that failed to stream images in the first run was retired again, and the drone that failed to take off was also removed. This adjustment created more vertical spacing between the drones, reducing the risk of mid-air collisions. With this configuration, two drones successfully entered the Unknown Search Area, while the remaining two flew past the Navigation Aids and veered into the Known and Pillar Area.
          </p>

        </div>

  
    </div>

      <div id="section-header-7" class="section" style="display: none;">
          <h2>7. Pillar Area (Matthew)</h2>
        Another new feature of SAFMC 2025 is the addition of the Pillar Area. This area of the playing field has no Inner Walls and only Pillars to form the obstacles that the drones must navigate across.
        <div id="sub-section-7-header-1">
          <h3>7.1 Introduction to the Pillar Area</h3>
          In the Pillar Area, there are no Inner Walls within to navigate around. This would mean that a different strategy from that used in the Known and Unknown Search Areas would be needed for the drone to navigate it and search for Victim Markers.
          <image-component tag="image" source="./assets/section-7-pillar-area/figure_7_1_pillar_area.png"
          subtitle="Figure 7.1: Pillar Area"></image-component>
        </div>
        <div id="sub-section-7-header-2">
          <br/>
          <h3>7.2 Mock-Up of the Pillar Area</h3>
          To test the Pillar Area, we need to build a mock-up of 8 Pillars in the area for our drones to navigate through. This was achieved using Styrofoam boards, which were tested to ensure that the drones can detect them while flying and can also fly in a stable manner near them. Both were found to be satisfactory with our Crazyflie drones. The dimensions of the pillar are about 30cm in diameter, close to the competition specification of 40cm. The height of the pillar are about 30-40cm, tall enough for our initially planned flying altitude of 30cm.
          <br/>
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/figure_7_2_mock_pillars.png"
          subtitle="Figure 7.2: Mock Pillars Used in The Arena, Left Was Wrapped with Paper to Get the Right Pillar on The Right Image"></image-component>
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/figure_7_3_testing_pillar_area.jpg"
          subtitle="Figure 7.3: Testing Of Pillar Area in IDP Studio 1 (Mention Height of The Chair / Chair + Pillar Combo)"></image-component>
          <br/>Later, the flying height was adjusted to 80cm which was found to be more robust and reliable. To support this new flying height, pillars were placed on chairs as seen in Fig 7.3 that were about 75cm in height. The pillar would now be in the range of 75 – 115cm off the ground.

        </div>
        <div id="sub-section-7-header-3">
          <h3>7.3 Testing of Search Strategies Within</h3>
          Without Inner Walls to follow, the search strategy relies on using the Pillars to localise the path of the drones as it flies within the area. A few methods were considered:
          <br/>
          A.	Using the MSBA wall following algorithm, but with changes to its speed
          <br/>
          One method explored was to use the same MSBA wall following algorithm with the speed reduced to 0.2 m/s. This worked on the theory that the drone would interpret the Pillars as walls till it comes to free space again, where it would return to its original heading. However, it was found that the drones would follow the Pillar’s circumference as a wall and end up going in an infinite loop.
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/figure_7_4_strat_A.png"
          subtitle="Figure 7.4: Description of Search Strategy A"></image-component>
          <br/>
          B.	Using an algorithm that follows the preferred direction till meeting a Pillar, avoiding it by following the circumference
          <br/>
          This method would involve having the drone first fly forward (which is its preferred direction) until it encounters a Pillar head-on, at which time it would avoid the Pillar by flying in a circular path following the walls of the Pillar. It would then resume its original heading after doing so in the new lane that it has corrected its flight path to. However, it tends to drift and cut the Pillar while doing so.
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/figure_7_5_strat_B.png"
          subtitle="Figure 7.5: Description of Search Strategy B"></image-component>
          <br/>
          C.	Using an algorithm that follows the preferred direction till meeting a Pillar, and avoids by turning on the spot
          <br/>
          Similarly to method B, the drones would fly in the preferred direction until it meets a Pillar head on. However, unlike the previous method, it would turn on the spot to the left or right by 90 ° and move for a short distance before turning back by another 90 ° to resume its flight in the original heading. This would avoid it cutting the Pillar while doing its “avoidance”, and is a solution developed together with David Chong, an Undergraduate Research Experience (UREx) student working alongside us on our project.
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/figure_7_6_strat_C.png"
          subtitle="Figure 7.6: Description of Search Strategy C"></image-component>
          <br/>
          <decision-matrix-pillar subtitle="Table 7.6: Comparison of three search strategies considered">
            <div id="decision-matrix-pillar"></div>
          </decision-matrix-pillar>
          </div>
        <div id="sub-section-7-header-4">
          <h3>7.4 Testing of Victim placement</h3>
          In the Pillar Area, targets were placed in different locations and the algorithm tested to ascertain the effectiveness of it to pick up the targets.
          <br/>
          1.	Target in free space
          <br/>
          Targets are placed in the middle of the pillar area in free space. Drones are seen to be able to detect and rescue these victims
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/victim_free_space.png"
                           subtitle="Figure 7.4.1: Victim in free space in the pillar area"></image-component>
          <br/>
          2.	Target in front of the pillar
          <br/>
          Another configuration involved placing the target directly in front of the pillar. Similarly to the one in free space, the drones had no issues picking up the victims in front of the pillar.
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/victim_front_pillar.png"
                           subtitle="Figure 7.4.2: Victim in front of the pillar"></image-component>
          <br/>
          3.	Target behind the pillar
          <br/>
          This was the hardest in theory to pick up since the drone would not be able to see the victim till it comes close to the target for the camera to pick it up. However, the drones were able to pick up and rescue the victims in the tests that we did. A failsafe however can be considered to increase the likelihood of rescuing the victim if it is not seen the first time that the drone passes through it.
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/victim_behind_pillar.png"
                           subtitle="Figure 7.4.3: Victim behind the pillar"></image-component>
          <br/>
        </div>
        <div id="sub-section-7-header-5">
          <h3>7.5 Optimising for Search and Rescue</h3>
          While Solution C was chosen as the ideal search strategy, further optimisations were made to maximise the coverage and reliability of the algorithm while minimising the search time. To achieve this, a few strategies were employed:
          <br/>
          <div id="sub-section-7-header-5-header-1">
            <h4>7.5.1 Sliding to the Side When Near a Pillar</h4>
            While the search strategy relies on avoiding a Pillar if it comes head-on to a Pillar, drift in the drone’s path can lead to it coming too close to Pillars on its side. A novel strategy was then employed for the drone to “slide” to the side should it come close to the Pillars, which would allow it to avoid collision with the Pillars while simultaneously maintaining the original heading of its flight path.
            <video-component tag="video" source="https://www.youtube.com/embed/X_Eua5u_tts?si=fUMhbO6se7Xcpaq0" subtitle="Figure 7.4: Video of drone sliding to the side when too close to the Pillar"></video-component>
          </div>

          <div id="sub-section-7-header-5-header-2">
            <h4>7.5.2 Optimising the speed of the drones</h4>
            Another parameter that we sought to optimise was the speed of the drones while flying within the pillar zone. Flying faster would mean that we are able to complete the mission in a quicker time, but would also increase the chance of crashing into pillars due to either slow or non-detection of the pillars while flying. This happens as the drones do require a processing time between detecting the pillars and avoiding it, and flying too fast would mean that the drones would crash into pillars before they are able to avoid it. Flying too slowly however would cause the mission to take too much time to complete.
            <br/>
            A speed of 0.5m/s was initially chosen. However, this was too fast leading to frequent crashes with drones. 0.2m/s was found to work well, but too slow. 0.25m/s was later found to be the optimal speed balancing speed with reliability of the algorithm.
            <br/>
          </div>

          <div id="sub-section-7-header-5-header-3">
            <h4>7.5.3 Navigation Aid to Reverse at the End of the Pillar Area</h4>
            Given the Pillar drones are optimised to carry out search and rescue in the Pillar Area, it should spend the duration of the mission searching the Pillar Area instead of drifting to other zones. Navigation Aids are therefore used at the end of the Pillar Area to send a command to reverse, which is like that employed in the Known Search Area. This would keep the drones “within” this area where it is best suited to search and capture targets that may have been placed directly behind a Pillar and missed in the first run.
            <image-component tag="image" source="./assets/section-7-pillar-area/figure_7_8_reverse.png"
            subtitle="Figure 7.8: Reverse"></image-component>

          </div>
          <div id="sub-section-7-header-5-header-4">
            <h4>7.5.4 Straight line vs Zig-Zag path</h4>
            The last parameter that we considered was whether the drone should fly in a straight-line path or a zig-zag one (as seen in the images below):
            <br/>
            <image-component tag="image" source="./assets/section-7-pillar-area/straight-vs-zigzag.png"
                             subtitle="Figure 7.9: Straight-line vs Zig-zag flight path"></image-component>
            <br/>
            By following a zig-zag path, we can increase the field of view of the camera with an intent to increase the reliability of target detection. However, this comes at the cost of more frequent crashes and an unpredictable flight path. After our testing, we found that this was not a good change and a straight line path would be more desirable given the trade-offs.
          </div>
        </div>

        <div id="sub-section-7-header-6">
          <h3>7.6 Full Algorithm</h3>
          Putting all together, we now have the following algorithm for search and rescue within the Playing Field for a single drone.
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/figure_7_9_1_full_algo.png"
          subtitle="Figure 7.10: Full Algorithm"></image-component>
          <br/>
          Based on our testing as seen in Figure 7.11, 3 drones flying with this algorithm are needed to achieve full search coverage of the pillar area while remaining robust and reliable. Any fewer drones would cause some search areas to be left uncovered, while allocating more drones may increase the chance of drone-to-drone collisions which would be counterproductive.
          <br/>
          <image-component tag="image" source="./assets/section-7-pillar-area/figure_7_9_2_full_algo.png"
          subtitle="Figure 7.11: Full Algorithm"></image-component>
          <br/>
          A video of the pillar test with 3 drones can be seen here:
          <br/>
          <br/>
          <video-component tag="video" source="https://www.youtube.com/embed/3jxxZiSw0ME?si=RA4qgXhqMRl-FVWZ" subtitle="Figure 7.12: Video of pillar test with 3 drones"></video-component>
        </div>
    </div>

      <br />
      <br />

      <div id="section-header-8" class="section" style="display: none;">
        <h2>8. Mission Planning (Shu Hui)</h2>


    <div id="sub-section-8-header-1">
        <h3>8.1 Optimisation of Take-off Sequence</h3>

        <image-component tag="image" source="./assets/section-8-mission-planning/figure_8_1_take_off_sequence.png"
        subtitle="Figure 8.1: Take-off Sequence"></image-component>

    </div>

    <div id="sub-section-8-header-2">
        <h3>8.2 Optimisation of Kill and Landing Sequence</h3>

    </div>

    <div id="sub-section-8-header-3">
      <h3>8.3 Communication Between the Ground Control Station and Drones</h3>

        <image-component tag="image" source="./assets/section-8-mission-planning/figure_8_3_communication_gcs_drones.png"
        subtitle="Figure 8.3: Communication Between the GCS and Drones"></image-component>

        <image-component tag="image" source="./assets/section-8-mission-planning/figure_8_4_detection_chart.png"
        subtitle="Figure 8.4: Detection Chart"></image-component>

  </div>

  </div>

  <br />
  <br />

      <div id="section-header-9" class="section" style="display: none;">
          <h2>9. Full-Scale Systems Testing</h2>


      <div id="sub-section-9-header-1">
          <h3>9.1 Testing in Residential College 4 Multi-Purpose Sports Hall</h3>
        To ascertain the accuracy and reliability of our overall search strategy, we conducted our full-scale testing at the Multi-Purpose Sports Hall of Residential College 4 (RC4 MPSH). RC4 MPSH’s dimensions was about 20 m x 20 m, providing a good approximation of the actual competition layout. This was also the first chance for us to test the search strategies for the Known, Unknown and Pillar search Areas all at once.
        <br/><br/>
        <image-component tag="image" source="./assets/section-9-full-scale-testing/figure_9_1_full_scale_rc4.jpg"
        subtitle="Figure 9.1: Full-Scale Testing Carried Out at RC4 MPSH"></image-component>
        <br/>
        In the RC4 MPSH, we first started by testing the algorithms without image streaming (no target detection). This allowed us to ascertain the feasibility of our search strategies and collision avoidance first.
        Later, we had a total of three runs testing the overall performance of the drone swarm with image streaming on to enable target detection and rescue of Victim Markers. The score of our three runs were:
        <br/><br/>
        <rc4-test-scores subtitle="Table 9.1: Test Scores in RC4">
          <div id="rc4-test-scores"></div>
        </rc4-test-scores>
        <br/>
        Run 3 was the best of all runs taken, where three Victim Markers were rescued (of which one is bonus) while none of the Danger Zones were within 1m of the drones after landing.
        <br/>
        Originally, we were not able to rescue any victims and score points as we faced a range of issues that hindered our drone swarm’s performance. These are described more in detail below, including how they were resolved as we improved in each run.
        <br/>

      <div id="sub-section-9-header-1-header-1">
        <h4>9.1.1 Network and Bandwidth Issues</h4>
        The original plan was to set up one central computer to manage all drones in the Playing Field, and it would do so on one Wi-Fi network with 3 routers. This would be up to 20 drones managed on one central system. While this was not an issue with individual system testing using up to 10 drones, it did not perform well with 20 at once which could have been due to overloading of the bandwidth. Drones would often either not connect to the Wi-Fi or do so then disconnect mid-flight. Once the Wi-Fi disconnects, the drones can no longer send images from the camera to the central system to process which means that it would not be able to rescue any victims.
        <br/>
        Eventually, a decision was made to change de-link the network into 3 separate components that would be controlled by 3 separate computers. This worked much better and gave us the assurance that the system would be reliable moving into the competition day.


      </div>

      <div id="sub-section-9-header-1-header-2">
        <h4>9.1.2 Different Performance of the Drones in Different Conditions</h4>
        Moving to RC4 MPSH, there were a few changes in conditions. First, the floor posed new challenges as it was shinier than the one seen in our IDP studio. This led to undefined behaviour of the drones, including speed-ups and inconsistent altitude observed. The drones were therefore not able to rescue Victim Markers or did so inconsistently, given that the speed varied drastically mid-flight.
        <br/>
        To counter this, we had to vary the distance of the drones to ensure the stable performance of them within the RC4 MPSH. By flying them higher, this would allow us to counter the effect of the reflective surface given that the drones are further from the ground.  By increasing the altitude from the original 30 cm to 80 cm, the drones were seen to perform in a much more stable manner. It could then fly in a much more predictable fashion allowing a more reliable search and rescue.
        <br/>


      </div>


      <div id="sub-section-9-header-1-header-3">
        <h4>9.1.3 Overall Analysis</h4>
        The conditions faced at RC4 MPSH were starkly different from that seen in individual component testing both due to the environment as well as the scale. It was therefore fortunate that we started the process early in Week 4, going to RC4 MPSH for a total of 4 times, which allowed us ample time to resolve the issues faced before going for the competition. The conditions at the actual competition, as described in the next paragraph, were found to be highly like that in the test here.
        <br/>
      </div>

      </div>

      <div id="sub-section-9-header-2">
          <h3>9.2 Competition Day</h3>
        On the 17th of March 2025, our team participated in SAFMC 2025 held at the Singapore Expo. This was the “final” full scale test with our full system being run all together.
        <br/>
        We were given two runs to test our drone swarm system with the better of the two runs taken as the final score. A total of 5 Victim Markers (of possible 8 as given in the rules) were used on the actual day, and likewise 3 Danger Zones (of possible 4) were used. The location of the Victim Markers and Danger Zones were not made known to us before placing our drones down and were only placed in the Playing Field after deciding on the placement of drones in the Playing Field. We only knew that the two Bonus Victims would be placed in the Pillar and Unknown Search Areas (one each) while the rest of the Regular Victims could be placed anywhere in the Playing Field.
        <br/>
        In the actual Playing Field, the performance of our drone swarm was like that exhibited on our final run at RC4 (conducted one week prior to the event) but with greater stability as the carpeted floor allowed the drones to fly in a much more stable manner. The results of the two runs are as follows:
        <br/><br/>
        <actual-test-scores subtitle="Table 9.2: Actual test scores @ SAFMC 2025">
          <div id="actual-test-scores"></div>
        </actual-test-scores>
        <br/><br/>
        Run 2 was taken as the final score given that it was the better of two runs. Given that we were able to rescue all but one Victim marker, we can conclude that our test environment was a good gauge of the actual Playing Field, with our search strategies and target detection working as intended in the actual competition.
        <br/><br/>
        <image-component tag="image" source="./assets/section-9-full-scale-testing/team_photo.jpg"
                         subtitle="Figure 9.2: Successful SAFMC 2025!"></image-component>
      </div>
    </div>

    <br />
    <br />

      <div id="section-header-10" class="section" style="display: none;">
          <h2>10. Conclusion and Future Work</h2>

        <div id="sub-section-10-header-1">
            <h3>10.1 Smart Stuff</h3>
        </div>
      </div>

    <br />
    <br />

      <div id="appendices" class="section" style="display: none;">
          <h2>Appendix A: Decision Matrix for Selection of Drone Development Platform</h2>


          <drone_platform_selection subtitle="">
            <div id="drone_platform_selection"></div>
          </drone_platform_selection>    

          <p> 
            The selection of drone platform was based on six equal-weighed key factors, size and weight, hardware modularity, software modularity, sensor capability, cost, and parts availability. For each factor, the drone platform is given a score out of 5, the higher the better.           
          </p>

          <ul style="list-style-type: decimal; padding: 0; margin: 0; text-align: justify;">
            <li>
              A smaller and lighter drone enhances manoeuvrability, especially in confined spaces, and improves swarm scalability. Among the evaluated platforms, the Bitcraze Crazyflie is the smallest and lightest, followed by the DJI Tello, which has a slightly larger size and higher weight.
              <br></br>
            </li>
            <li>
              A modular hardware design allows for easy upgrades and component replacements. Higher scores indicate greater flexibility in adding or replacing components. Crazyflie and DEXI are highly modular, as both suppliers provide spare parts and easily swappable components. DEXI scores higher since certain parts, like its onboard computer (Raspberry Pi), are off-the-shelf, whereas Bitcraze relies on a custom PCB. DJI Tello, in contrast, only offers spare parts for specific components like propellers and propeller guards.
              <br></br>
            </li>
            <li>
              Open-source software and compatibility with frameworks like ROS are crucial to provide better software flexibility, developer support, and ease of integration. Crazyflie and DEXI both have high scores as both have open-source software. However, DEXI ranks higher as its on-board computer (Raspberry Pi) provides greater processing power and flexibility compared to Crazyflie’s STM microcontroller. DJI Tello has a low score of 2 due to it running on a proprietary software.
              <br></br>
            </li>
            <li>
              The drone must support onboard sensors for localization, obstacle detection, and avoidance. A higher score is given to platforms with more built-in or easily integrable sensors.  Crazyflie and DEXI have high scores as both offer the same sensor suite such as optical flow sensors, multi-TOF distance sensors, camera etc. On the other hand, DJI Tello only contains a camera module, limiting its capabilities to vision-based solutions.
              <br></br>
            </li>
            <li>
              The cost of each platform should be reasonable as they will be scaled up to form a swarm. In terms of pricing per unit, DJI Tello is the most affordable at USD 109, while Crazyflie, including the additional sensor decks cost USD 640. The DEXI Level III is the most expensive at USD 2000.
              <br></br>
            </li>
            <li>
              Readily available drones and spare parts ensure ease of maintenance. DJI and Bitcraze both have authorized retailers in Singapore, making their spare parts highly accessible. However, DEXI only operate in the United States, requiring international shipping for spare parts, which leads to increased lead time and cost.
              <br></br>
            </li>
          </ul>

      </div>

    <br />
    <br />
 
    <div id="references" class="section" style="display: none;">
      
      <h2>References</h2>
      <ul style="list-style-type: decimal; padding: 0; margin: 0; text-align: justify;">

         <li>
          Loco explorer bundle—Crazyflie 2.1+. (n.d.). Bitcraze Store. Retrieved 29 March 2025, from https://store.bitcraze.io/products/loco-explorer-bundle
         </li>
         <li>
          Maximum range for loco positioning | Bitcraze. (n.d.). Retrieved 29 March 2025, from https://www.bitcraze.io/documentation/system/positioning/max-range-loco/
         </li>
         <li>
          Comparison of fiducial markers. (2022, April 26). Robotics Knowledgebase. https://roboticsknowledgebase.com/wiki/sensing/fiducial-markers/
         </li>
         <li>
          Aideck-gap8-examples/examples/other/wifi-img-streamer at master · bitcraze/aideck-gap8-examples. (n.d.). GitHub. Retrieved 29 March 2025, from https://github.com/bitcraze/aideck-gap8-examples/tree/master/examples/other/wifi-img-streamer
         </li>
         <li>
          AprilRobotics/apriltag. (2025). [C]. AprilRobotics. https://github.com/AprilRobotics/apriltag
         </li>
         <li>
          Freertos+posix—FreertosTM. (n.d.). Retrieved 29 March 2025, from https://freertos.org/Documentation/03-Libraries/05-FreeRTOS-labs/03-FreeRTOS-plus-POSIX/00-FreeRTOS-Plus-POSIX
         </li>
         <li>
          Tl-nus-cfs/ai_deck_wrapper. (2023). [Python]. TL@NUS Centre For Flight Sciences. https://github.com/TL-NUS-CFS/ai_deck_wrapper
         </li>
         <li>
          Rauch, C. (2025). Christianrauch/apriltag_ros [C++]. https://github.com/christianrauch/apriltag_ros
         </li>
         <li>
          Rauch, C. (2025). Christianrauch/apriltag_msgs [CMake]. https://github.com/christianrauch/apriltag_msgs
         </li>
         <li>
          Github—Cde-4301-asi-401/missionplanner. (n.d.). GitHub. Retrieved 29 March 2025, from https://github.com/CDE-4301-ASI-401/MissionPlanner
         </li>
         <li>
          GitHub—Williamleong/aideck-gap8-examples at dev/william. (n.d.). GitHub. Retrieved 29 March 2025, from https://github.com/williamleong/aideck-gap8-examples
         </li>
         <li>
          Release 2025.02 · bitcraze/aideck-esp-firmware. (n.d.). GitHub. Retrieved 29 March 2025, from https://github.com/bitcraze/aideck-esp-firmware/releases/tag/2025.02
         </li>
         <li>
          BigQuad deck | Bitcraze. (n.d.). Retrieved 2 April 2025, from https://www.bitcraze.io/products/bigquad-deck/
         </li>
         <li>
          Prototyping deck | Bitcraze. (n.d.). Retrieved 2 April 2025, from https://www.bitcraze.io/products/prototyping-deck/
         </li>
         <li>
          MissionPlanner/mission_planner/kill_all.py at main · CDE-4301-ASI-401/MissionPlanner. (n.d.-a). GitHub. Retrieved 29 March 2025, from https://github.com/CDE-4301-ASI-401/MissionPlanner/blob/main/mission_planner/kill_all.py
         </li>
         <li>
          MissionPlanner/mission_planner/mission_script.py at main · CDE-4301-ASI-401/MissionPlanner. (n.d.). GitHub. Retrieved 29 March 2025, from https://github.com/CDE-4301-ASI-401/MissionPlanner/blob/main/mission_planner/mission_script.py
         </li>

      </ul>
    </div>

  </div>
  </div>

  <sl-button class="scroll-to-top" variant="primary" size="medium" circle onclick="scrollToTop()">
    <sl-icon name="arrow-up" label="Settings"></sl-icon>
  </sl-button>

  <script src="https://unpkg.com/gridjs/dist/gridjs.umd.js"></script>
  
  <script type="module" src="./components/table-component/table-component.js"></script>

  <script src="showhidefunction.js"></script>

</body>

</html>
